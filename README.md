아래는 지금까지 논의한 컨셉과 방향을 반영한 **실사용 가능한 README 초안**입니다.
GitHub 저장소 메인 문서로 그대로 써도 될 수준으로 작성했습니다.

---

# 📰 Daily Digest – 오늘, 이 정도만 알면 충분합니다

> **정보 과잉 시대를 위한 미니멀 뉴스 큐레이션**

Daily Digest는
“많이 보여주는 뉴스 서비스”가 아니라
**꼭 필요한 것만 남기는 뉴스 서비스**입니다.

하루에 단 5개의 뉴스로
3분 안에 오늘을 정리할 수 있도록 설계되었습니다.

---

## 🎯 서비스 목표

우리는 이런 문제를 해결하고자 합니다.

* 하루 수백 개의 뉴스 알림으로 인한 피로감
* 클릭 수를 노린 자극적 헤드라인
* 읽어도 기억에 남지 않는 단발성 소식
* 중요한 정보와 소음의 혼재

### 그래서 이렇게 만듭니다

Daily Digest는 다음 기준으로만 뉴스를 선정합니다.

1. **내일도 영향이 남는 이슈**
2. **과도한 감정 소모를 유발하지 않는 정보**
3. **어제와 중복되지 않는 내용**

---

## ✨ 핵심 차별점

### 1) 알고리즘 중심이 아닌 ‘편집 철학’ 중심

* 클릭 수 기반 추천이 아닙니다.
* 체류 시간을 늘리기 위한 설계가 없습니다.
* 감정을 자극하는 기사보다
  **결정에 도움되는 기사**를 우선합니다.

### 2) 하루 5개로 강제 제한

* 많이 보여주는 대신 **적게 보여줍니다**
* “다 봤다”는 느낌을 주는 분량
* 뉴스 소비의 부담을 의도적으로 줄입니다

### 3) 요약 + 맥락 중심 구성

각 뉴스는 항상 다음 형식으로 제공됩니다.

* 핵심만 담은 **3줄 요약**
* “왜 중요한가” 한 문장 설명
* 읽는 데 걸리는 예상 시간
* 원문 링크

---

## 🧭 선정 주제 범위

Daily Digest는 주로 다음 영역에 집중합니다.

### IT

* AI, 반도체, 클라우드, 보안
* 기술 정책과 규제
* 산업 구조 변화

### 경제

* 거시경제 변화
* 기업 실적과 가이던스
* 에너지·금융 시장

### 글로벌

* 국제정세와 무역
* 제재·관세 정책
* 지정학적 이벤트

연예, 가십, 사건사고, 감정 자극형 뉴스는 의도적으로 배제합니다.

---

## 🛠 기술 구성

* **Frontend**: React + TypeScript (SPA)
* **Data Pipeline**: Python 기반 뉴스 수집/필터링
* **Automation**: GitHub Actions로 매일 자동 큐레이션
* **Data Source**: 공개 RSS 피드
* **Output**: 정적 JSON 데이터

### 구조 개요

```
RSS 수집 → 점수화 필터링 → 중복 제거 → 상위 5개 선별
→ AI 요약 정제 → JSON 생성 → 프론트엔드 반영
```

모든 과정은
최소 비용 + 자동 운영을 목표로 설계되었습니다.

---

## 📐 큐레이션 원칙

뉴스 중요도는 다음 기준으로 평가됩니다.

* 구조적 영향력
* 정책/규제 변화
* 산업 전반에 미치는 파급력
* 단순 화제성은 감점 요소

각 기사는 반드시 다음 정보를 포함합니다.

* 3줄 요약
* 중요성 설명
* 중요도 점수
* 영향 신호(정책/실적/수요 등)

---

## 🚫 의도적 제외

이 서비스에는 다음이 없습니다.

* 실시간 속보
* 푸시 알림
* 개인화 추천
* 댓글/커뮤니티
* 자극적 광고

---

## 👤 누구를 위한 서비스인가

* 뉴스를 챙겨보고 싶지만 시간이 부족한 사람
* 정보 과잉에 지친 직장인
* 매일 아침 핵심만 빠르게 파악하고 싶은 사람
* 감정 소모 없는 뉴스 소비를 원하는 사용자

---

## 🌱 로드맵

### 현재 단계

* 자동 뉴스 수집
* AI 기반 요약
* 최소한의 UI로 운영

### 향후 계획

* 아카이브 기능 강화
* SEO 최적화
* 주간 요약 제공
* 큐레이션 품질 지속 개선

---

## 💬 철학 한 줄

> 더 많이 아는 것보다
> **덜 보고 제대로 아는 것이 더 똑똑한 소비입니다.**

---

## 📄 라이선스

MIT License
